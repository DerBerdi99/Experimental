{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only works for a certain nvidia gpu\n",
    "conda install faiss-gpu required\n",
    "\n",
    "Let’s try to build our own (small scale) Google Image Search! For that, we need to:\n",
    "Convert the images into embeddings (=vectors) with Clip\n",
    "Index the image vectors with Faiss\n",
    "Build the image search using the data from the previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "img_model=SentenceTransformer('clip-ViT-B-32')\n",
    "images=[Image.open('/Users/oliverzimmermann/Desktop/VisKomm3_A5/Berthold.Hannes.VK3.WiSe23.A5/Berthold.Hannes.VK3.WiSe23.A5_8.jpg')]\n",
    "embeddings=img_model.encode(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding a single image takes ~20 ms with a single Nvidia V100 GPU and 1 million images takes ~90 minutes. With a large number of images, it’s good to encode the images in larger batches to minimize the overhead of sending the data to the GPU.\n",
    "To efficiently look up the most similar images for a given text query, we need to index them. -> Faiss. Faiss is a library from Facebook for efficient similarity search and clustering of dense vectors. It offers many different functionalities, such as:\n",
    "Basic vector similarity search without any clustering or compression\n",
    "Partitioned index with Voronoi cells to do an approximate search (to speed up the search)\n",
    "Vector compression using product quantization (to reduce the memory footprint)\n",
    "Building the index\n",
    "I chose the IndexIVFFlat index type, which creates a partitioned index to allow faster lookup. The vectors are grouped into clusters (Voronoi cells) and the search checks the vectors from the best cluster(s). Which allows faster searches but might not always return the most accurate results. You can balance between speed and accuracy by choosing the number of clusters but also how many clusters to visit when searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'faiss' has no attribute 'StandardGpuResources'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m params\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIVF\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcells\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstorage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m index\u001b[38;5;241m=\u001b[39mindex_factory(DIMENSIONS,params)\n\u001b[0;32m---> 10\u001b[0m res\u001b[38;5;241m=\u001b[39m\u001b[43mfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStandardGpuResources\u001b[49m()\n\u001b[1;32m     11\u001b[0m index\u001b[38;5;241m=\u001b[39mfaiss\u001b[38;5;241m.\u001b[39mindex_cpu_to_gpu(res,\u001b[38;5;241m0\u001b[39m,index)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'faiss' has no attribute 'StandardGpuResources'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import faiss\n",
    "from faiss import index_factory\n",
    "COUNT = embeddings.shape[0]\n",
    "DIMENSIONS = embeddings.shape[1]\n",
    "storage='Flat'\n",
    "cells=min(round(math.sqrt(COUNT)),int(COUNT/39))\n",
    "params=f\"IVF{cells},{storage}\"\n",
    "index=index_factory(DIMENSIONS,params)\n",
    "res=faiss.StandardGpuResources()\n",
    "index=faiss.index_cpu_to_gpu(res,0,index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index_factory function allows building those composite indexes easily since we need an index to find the best cluster and then another index for the vectors in the cluster.\n",
    "The training just finds the most optimal cluster centroids so you don’t necessarily need to train it with all the indexes. I’m also adding the vectors to the index with IDs so it will be easier to look up the actual image files. The ID is just a unique random number which will be also used as the filename of the image on GCS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=[12345]\n",
    "filenames=[f\"gs://<bucket>/images/{id}.jpg\" for id in ids]\n",
    "index.train(embeddings)\n",
    "index.add_with_ids(embeddings, ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image search\n",
    "Finding for the most similar images for the given text is just a vector similarity search:\n",
    "Convert the text into a query vector\n",
    "Find the most similar vectors from the index for the query vector\n",
    "Lookup the image files from GCS using the (image) vector ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model=SentenceTransformer('sentence-transformers/clip-ViT-B-32-multilingual-v1')\n",
    "query='men playing soccer'\n",
    "embedding=text_model.encode([query])\n",
    "def normalize_L2(embedding):\n",
    "    k=0\n",
    "    for i in embedding:\n",
    "        j=i*i\n",
    "        k+=j\n",
    "    l=math.sqrt(k)\n",
    "    for i in range(len(embedding)):\n",
    "        embedding[i]=embedding[i]/l\n",
    "    return embedding\n",
    "    \n",
    "probabilities,ids=index.search(embedding,COUNT)\n",
    "ids=ids[0]\n",
    "probabilities=probabilities[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
